in this video I'm going to discuss the differences between the gradient operator and the D operator I'd highly recommend looking at the description for a link to my video on raising and lowering tensor indexes before watching this one since I'm going to be building on the ideas from that video so in this tensor calculus series I've been talking about two different operators that act on functions there is the gradient operator also called the del operator and there is the D operator and these two operators are highly related but they are technically different and I'd like to compare and contrast them unfortunately there's some confusion in the math and physics community about what these operators are actually called some sources like this textbook called gravitation actually called DF the gradient of F while various articles on Wikipedia give DF different names like the exterior derivative and differential one form to add to the confusion and some articles Wikipedia calls the gradient a vector field and in other articles it calls the gradient a co vector field for the purposes of this video I'm going to be calling this symbol del F or also sometimes the gradient of F and I'm going to be calling this symbol DF and also sometimes the differential of F or sometimes the exterior derivative of F so there may be some sources you come across that call this the gradient of F but for the purposes of this video when I talk about the gradient of F I'm talking about this symbol here so both the gradient operator and the D operator act on scalar fields now the difference is that the gradient of a scalar field gives us a vector field where the vectors point in the direction of steepest increase with larger vectors indicating a steeper change on the other hand DF gives us a co vector field also called a one form where the co vector curves are given by the level sets of the function f and the level sets are oriented towards the positive values of F so del F and DF are clearly different del F as a vector field and DF is a co vector field so these two ideas are clearly different but they're also fairly similar we can see that the orientation of these vectors and these Co vectors are the same both of them point towards the positive values of the function f also the larger vectors which are shown by long arrows in this image match up with large Co vectors which are shown by densely packed curves in this image likewise these smaller vectors which are short match up with these smaller Co vectors which are sparsely spaced curves so again del F and DF are different concepts but they're also highly related so what's the connection between the two well in my previous video on raising and lowering tensor indexes I talked about how there was a special connection between the vector space V and the dual space of Co vectors V star and the connection is made by taking the vector V in our vector space and partnering it with the co vector V dot something in the dual space so this V dot something is like a dot product with an empty slot on the right hand side that's waiting to eat another vector and when we give it another vector it will produce a scalar now it turns out we can make a very similar connection between dehl F and DF so I'll show you what I mean so recall that when the co vector DF acts on the vector V it gives us the directional derivative of F in the direction of the vector V and another way of writing the directional derivative of F relative to a velocity vector V is like this and we know that to compute the directional derivative we can just take the dot product between the gradient of F and the velocity vector V so this is interesting on the Left we have DF acting on a vector V and on the right we have the gradient of F with a dot product acting on the vector V so in a sense this means that DF is equal to del F dotted with something right these are both functions that take a vector input and produce a scaler and when we plug in the same vector into each we get the same answer the directional derivative so DF + del F dot something are actually the same function so just as we can pair up a vector V with a partner Co vector V dot something we can also partner the vector field del F with the partner Co vector field del F dot something and this is equal to the cove Ector field DF so DF is the dual code vector field of the vector field del F which in this video I call the gradient of F so if you were called from my previous video on raising and lowering indexes when we had vector and Kovach turk art nur's the way we changed from V to V dot something was by using the metric tensor and the reverse process to go in the other direction was done using the inverse metric tensor where the components of the inverse metric tensor are defined by this formula here where when we do a summation with the components of the ordinary metric tensor we get the Kronecker Delta so let's just remind ourselves how we can use the metric tensor to change between the vector V and the co vector V dot something well recall that to compute the dot product V dot W we can just expand out the vectors as linear combinations of basis vectors in a given basis so we have the vector components here and the basis vectors here and if we like we can rewrite these linear combinations using Einstein notation with implied summations over I so if we write this dot product we can expand V and W out as linear combinations using the Einstein notation and this dot product of the basis vectors just gives us the metric tensor components so we can see that the key to computing the W is done using the components of V and W as well as the components of the metric tensor now if we want to compute V dot something we just remove the vector W from the input slot of the dot product here and likewise get the full component expansion of V dot something we can take this formula here and just sort of remove the W vector components and get this and you'll notice I've added these epsilon J's here these epsilon J's are the co vector bases for the dual space defined by this formula here so I do any more proper derivation of this expression in my tensors for beginners video number 16 on raising and lowering tensor indexes but for this video I'm just going to sort of wave my hand and hope that you can believe me when I say when we're trying to construct this Cove Ector we need to expand it out in a Cove Ector basis which are the epsilon s-- and the components of this Cove Ector would be these components here so we can in fact see that the metric tensor components help us convert the vector components of V into the co vector components of V dot something so just as we learned in the video on raising and lowering tensor indexes when we have the vector V and the co vector V dot something we can use the metric tensor to convert between components of V and components of V dot something and to go in the opposite direction we use the inverse metric tensor whose components are defined by this summation equation here with the metric tensor components and the Kronecker Delta so just as this is true with the vector V and the co vector B dot something this is also true with the vector field Dell F and the co vector field D F which is really just del F dot something so I'll show you why this is true so we know that the directional derivative DF of E is equal to the gradient of F also called del F dotted with the vector V and we can expand each of these vectors out in the Cartesian basis using the Cartesian basis vectors so this here is just the eighth component of the vector V and this here is just the ice component of the gradient vector del F and we can bring the components outside and write is thought product of the basis vectors and now this dot product of basis vectors just gives us the metric tensor components so this formula right here is the formula for the directional derivative now notice here that both DF and del F are acting on the vector V so if we like we can just remove the vector V from these formulas to get a co vector so both DF and del F dot something are Co vectors and to get this summation formula for this Cove Ector we just remove the V components and replace them with the co vector basis DC J so since we're building a Co vector we need to build these out of basis Co vectors so we're adding the basis Co vectors DC J so if you're confused about following this step right here that's because I'm sort of waving my hand and not giving the full explanation for why this is true a full explanation of this line of reasoning requires an understanding of the tensor product so I'm actually going to include the proof for this line of reasoning in my next video since it will require a little bit of time to explain but for now you're just gonna have to trust me that this is true and just believe that since these are Co vectors we need to build them out of basis Co vectors which are the DC J's here alright so we know from our previous videos that the DF Co vector field can be expanded out in the Cove Ector basis like this where these partial derivatives are the components so we've discovered that DF is equal to two different things there's this formula right here which is the expansion in the co vector basis and there's this formula here which uses the components of del of F and the metric tensor components so DF is equal to both of these formulas here now notice that both of these formulas involve the basis Co vectors DC J so if these formulas are equal that means that their components must also be equal so we get this equation between the components with partial derivatives on the left hand side and a summation over the components del F and the metric tensor components okay so here we have in fact confirmed that the metric tensor components help us change between the components of the vector field del F and the components of the co vector fields DF which are these partial derivatives here now it would be nice if we could isolate the components of del F on one side so we need to get rid of these metric tensor components now to do that we just remember the definition of the inverse metric tensor components here and we can see that this gives us the Kronecker Delta so if we do summations on both sides using the inverse metric tensor components we can change this term here into the Kronecker Delta I K and by the chroniker delta index cancellation rule we can cancel out these eye indexes and just write this as K all right so basically what we've done is we've derived a formula for the components of del F and these end up being equal to these partial derivatives summed up with the components of the inverse metric tensor okay so we can see that the inverse metric tensor really does take us from the components of DF which are these partial derivatives to the components of del F or the gradient of F and this formula here is really interesting because it gives us the true formula for the components of del F or the gradient of F so we can write the gradient of F as a linear combination of these basis vectors where these components are equal to this term here or if you prefer we can write it in the alternative vector notation where the basis vectors would look like this now you might be a bit surprised by this formula because you've probably calculated the gradient many times before but never seen the inverse metric tensor components here like this so do these inverse metric tensor components really belong in here well recall that in the Cartesian basis the basis vectors are orthonormal so the metric tensor components are just the Kronecker Delta is a bit like the identity matrix and that means that the components of the inverse metric tensor are also the Kronecker Delta and so that also gives us the identity matrix so if we use this formula for del F or the gradient of F this inverse metric tensor just becomes a Kronecker Delta and we can use the cancellation rule to cancel DJ's here and get K and then we get this formula and if we write out this summation over K explicitly we can see that we get our familiar old formula for the gradient in Cartesian coordinates now in polar coordinates the metric tensor looks like this matrix as we calculated back in video 11 in this tensor calculus series so that means that the inverse metric tensor looks like this so because the matrix is diagonal we can just take the reciprocal of the diagonal elements to get the inverse matrix so that means when we take this formula for del F or the gradient of F all of the off diagonal elements are 0 so this summation ends up only having two terms the RR term and the theta theta term so with these inverse metric tensor components this is just 1 and this is just 1 over R squared so the formula for del F or the gradient of F in polar coordinates actually looks like this where we need this extra 1 over R squared term to make things correct and again I might remind you that my definition of the e theta basis vector is not normalized so it gets longer as we move farther away from the origin a lot of textbooks will normalize the e theta basis vector by dividing by R so that it has length 1 and if you're using this definition of the e theta basis vector then you would end up with only 1 over r here instead of 1 over R squared but my point is that the formula for del F or the gradient of F looks like a linear combination of basis vectors with these partial derivatives but depending in which coordinate system we're using we might end up extra terms like this one over R squared term in polar coordinates and we sometimes need these extra terms in order to get the formula for the gradient right in that coordinate system and these extra multiplying terms actually come from the components of the inverse metric tensor so it turns out that these inverse metric tensor components really do belong in this formula for the gradient of F or del F right in the Cartesian coordinate system the inverse metric tensor just ends up being the identity matrix so we don't need any extra terms other than the partial derivatives and this means that the components of del F end up being the exact same as the components of DF but in other coordinate systems we might not be so lucky and we might need extra terms so if you've ever seen the formula for the gradient in spherical coordinates you probably know that it looks a little bit crazy with all these extra terms here and all these extra terms actually just come from the inverse metric tensor components so the inverse metric tensor really does help us get the gradient formula right in every coordinate system so in your multivariable calculus classes you might have derived all these terms manually by doing a bunch of substitutions and coordinate changes but in tensor calculus we like to think of these extra terms as just the components of the inverse metric tensor so to summarize this video if we have some scalar field F then del F or the gradient of F is a vector field where the arrows point along the direction of greatest increase and DF also called the differential of F or the exterior derivative of F is a co vector field which is basically like the level sets of F oriented towards positive values and just as we can pair a vector V with a partner Co vector V dot something we can also pair the vector field del F with the co vector field del F dot something which also turns out to be equal to DF and to move back and forth between vectors and partner Co vectors we just used the metric tensor and to go in the opposite direction from Co vectors to partner vectors we use the inverse metric tensor whose components are defined by this equation so more concretely to go back and forth between the components of del F and DF we can use these two formulas here with the metric tensor components and inverse metric tensor components and I'd like to add one last point about notation so the normal notation for switching between del F and DF is normally done using the letter G for the metric tensor and the inverse metric tensor but there's also this alternative notation I introduced in my video on raising and lowering indexes that involves the flat and sharp symbols from music so the flat operator can also be used to change del F into DF and the sharp operator can be used to change from DF into del F so this sharp flat notation is a bit strange but you might see it in some textbooks or online articles so in the next video I'm going to more carefully go over the proof of why this formula for del F dot something makes sense and that will be done using tensor products and I'll also give a concrete example of computing the components of del F in two different coordinate systems